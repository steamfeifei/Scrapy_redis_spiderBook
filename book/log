2019-05-12 21:47:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/1451819577.html> (referer: http://category.dangdang.com/cp01.10.05.00.00.00.html)
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\workspace\NLP2\骚操作\distributed_book\book\book\spiders\dangdang.py", line 97, in parse_book_detail
    prodSpuInfo = json.loads(prodSpuInfo[0])
  File "E:\python36\lib\json\__init__.py", line 354, in loads
    return _default_decoder.decode(s)
  File "E:\python36\lib\json\decoder.py", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "E:\python36\lib\json\decoder.py", line 355, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 793 (char 792)
2019-05-12 22:05:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://product.dangdang.com/1292604187.html> (referer: http://category.dangdang.com/cp01.06.10.00.00.00.html)
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\workspace\NLP2\骚操作\distributed_book\book\book\spiders\dangdang.py", line 97, in parse_book_detail
    prodSpuInfo = json.loads(prodSpuInfo[0])
  File "E:\python36\lib\json\__init__.py", line 354, in loads
    return _default_decoder.decode(s)
  File "E:\python36\lib\json\decoder.py", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "E:\python36\lib\json\decoder.py", line 355, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting ',' delimiter: line 1 column 1087 (char 1086)
2019-05-13 08:40:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://static.dangdang.com/503error/error.html> (referer: http://category.dangdang.com/cp01.43.76.00.00.00.html)
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\python36\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\workspace\NLP2\骚操作\distributed_book\book\book\spiders\dangdang.py", line 97, in parse_book_detail
    prodSpuInfo = json.loads(prodSpuInfo[0])
IndexError: list index out of range
2019-05-13 09:14:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:14:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:16:16 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/25259950.html>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2019-05-13 09:16:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/25259300.html>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:06 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25252408&categoryPath=01.41.05.03.00.00&mainProductId=25252408&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25248903&categoryPath=01.66.11.00.00.00&mainProductId=25248903&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25260731&categoryPath=01.66.10.00.00.00&mainProductId=25260731&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25261323&categoryPath=01.41.26.03.00.00&mainProductId=25261323&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25208908&categoryPath=01.66.11.00.00.00&mainProductId=25208908&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-05-13 09:17:24 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25251670&categoryPath=01.55.50.19.00.00&mainProductId=25251670&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25261324&categoryPath=01.41.26.03.00.00&mainProductId=25261324&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-05-13 09:17:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25261327&categoryPath=01.41.26.03.00.00&mainProductId=25261327&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:17:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25261325&categoryPath=01.41.26.03.00.00&mainProductId=25261325&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseNeverReceived: [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion.>]
2019-05-13 09:17:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25259302&categoryPath=01.41.27.09.00.00&mainProductId=25259302&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:18:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://product.dangdang.com/index.php?r=comment%2Flist&productId=25261326&categoryPath=01.41.26.03.00.00&mainProductId=25261326&mediumId=0&pageIndex=4&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish>
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 10060: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。.
2019-05-13 09:22:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 1001, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:07 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:12 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:17 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:37 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:42 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:52 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:23:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:07 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:12 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:17 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:37 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:42 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:52 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:24:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:07 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:12 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:17 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:37 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:42 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:52 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:25:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:07 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:12 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:17 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:37 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:42 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 09:26:52 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:33 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:36 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:37 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:15:38 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:15:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:41 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:43 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:46 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:48 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:48 [scrapy.core.scraper] ERROR: Error processing {'level_one_name': ['科技', '科普', '建筑', '医学', '计算机', '农林', '自然科学', '工业'], 'level_two_name': ['医学'], 'level_three_name': ['医学工具书'], 'level_three_urls': 'http://category.dangdang.com/cp01.56.54.00.00.00.html', 'depth': 4, 'download_timeout': 180.0, 'download_slot': 'category.dangdang.com', 'download_latency': 5.7177135944366455, 'detail_url': 'http://product.dangdang.com/23941747.html', 'proxy': 'http://112.27.167.74:33641', 'b_name': ['临床检验装备大全 第3卷   试剂与耗材  上册'], 'b_detail': [], 'b_author': '丛玉隆陈文祥高尚先毕少辉', 'b_press': [], 'b_price': ['237.00'], 'b_comment': [], 'comment_nums': ['全部'], 'b_comment_short_url': 'http://product.dangdang.com/index.php?r=comment%2Flist&productId=23941747&categoryPath=01.56.56.00.00.00&mainProductId=23941747&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish', 'b_comment_short_strs': ['好评 '], 'b_comment_long_url': 'http://product.dangdang.com/index.php?r=comment%2Flist&productId=23941747&categoryPath=01.56.56.00.00.00&mainProductId=23941747&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long', 'b_comment_long_strs': []}
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\python\threadpool.py", line 250, in inContext
    result = inContext.theWork()
  File "E:\python36\lib\site-packages\twisted\python\threadpool.py", line 266, in <lambda>
    inContext.theWork = lambda: context.call(ctx, func, *args, **kw)
  File "E:\python36\lib\site-packages\twisted\python\context.py", line 122, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "E:\python36\lib\site-packages\twisted\python\context.py", line 85, in callWithContext
    return func(*args,**kw)
  File "E:\python36\lib\site-packages\scrapy_redis\pipelines.py", line 66, in _process_item
    self.server.rpush(key, data)
  File "E:\python36\lib\site-packages\redis\client.py", line 1666, in rpush
    return self.execute_command('RPUSH', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 1001, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:15:48 [scrapy.core.scraper] ERROR: Error processing {'level_one_name': ['科技', '科普', '建筑', '医学', '计算机', '农林', '自然科学', '工业'], 'level_two_name': ['自然科学'], 'level_three_name': ['科技史'], 'level_three_urls': 'http://category.dangdang.com/cp01.62.15.00.00.00.html', 'depth': 4, 'download_timeout': 180.0, 'download_slot': 'category.dangdang.com', 'download_latency': 2.696784734725952, 'detail_url': 'http://product.dangdang.com/23844400.html', 'proxy': 'http://112.27.167.74:33641', 'b_name': ['李约瑟中国科学技术史4-3土木工程与航海技术'], 'b_detail': [], 'b_author': '胡维佳汪受琪', 'b_press': [], 'b_price': ['383.20'], 'b_comment': [], 'comment_nums': ['全部'], 'b_comment_short_url': 'http://product.dangdang.com/index.php?r=comment%2Flist&productId=23844400&categoryPath=01.62.15.00.00.00&mainProductId=23844400&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish', 'b_comment_short_strs': ['刚刚拿到手，忍不住翻阅，略略读了一篇，李约瑟好博学，治学严谨，长知识了！这是一个令人敬佩的人写成的一部伟大的作品，非常值得推荐！', '中国科学技术史，非常好的丛书，第二次印刷，才能重新收集到没有收集到的书籍。 ', '确实不俗，扎实研究和行文，才影响力这么大。', '包装完好，发货及时，图书质量有保证', '帮领导买的书看不懂但是书应该是正品', '书是活动期间买的，还好吧'], 'b_comment_long_url': 'http://product.dangdang.com/index.php?r=comment%2Flist&productId=23844400&categoryPath=01.62.15.00.00.00&mainProductId=23844400&mediumId=0&pageIndex=1&sortType=1&filterType=1&isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=long', 'b_comment_long_strs': []}
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\python\threadpool.py", line 250, in inContext
    result = inContext.theWork()
  File "E:\python36\lib\site-packages\twisted\python\threadpool.py", line 266, in <lambda>
    inContext.theWork = lambda: context.call(ctx, func, *args, **kw)
  File "E:\python36\lib\site-packages\twisted\python\context.py", line 122, in callWithContext
    return self.currentContext().callWithContext(ctx, func, *args, **kw)
  File "E:\python36\lib\site-packages\twisted\python\context.py", line 85, in callWithContext
    return func(*args,**kw)
  File "E:\python36\lib\site-packages\scrapy_redis\pipelines.py", line 66, in _process_item
    self.server.rpush(key, data)
  File "E:\python36\lib\site-packages\redis\client.py", line 1666, in rpush
    return self.execute_command('RPUSH', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:15:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:53 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:55 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:15:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:15:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:15:57 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:15:57 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:15:58 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:11 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:13 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:13 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:16:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:16:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:15 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:16:15 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:16:16 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:18 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:23 [twisted] CRITICAL: Unhandled error in Deferred:
2019-05-13 10:16:23 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\redis\connection.py", line 492, in connect
    sock = self._connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 550, in _connect
    raise err
  File "E:\python36\lib\site-packages\redis\connection.py", line 538, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python36\lib\site-packages\twisted\internet\task.py", line 517, in _oneWorkUnit
    result = next(self._iterator)
  File "E:\python36\lib\site-packages\scrapy\utils\defer.py", line 63, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "E:\python36\lib\site-packages\scrapy\core\scraper.py", line 183, in _process_spidermw_output
    self.crawler.engine.crawl(request=output, spider=spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 210, in crawl
    self.schedule(request, spider)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 216, in schedule
    if not self.slot.scheduler.enqueue_request(request):
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 162, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "E:\python36\lib\site-packages\scrapy_redis\dupefilter.py", line 100, in request_seen
    added = self.server.sadd(self.key, fp)
  File "E:\python36\lib\site-packages\redis\client.py", line 1878, in sadd
    return self.execute_command('SADD', name, *values)
  File "E:\python36\lib\site-packages\redis\client.py", line 772, in execute_command
    connection = pool.get_connection(command_name, **options)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.
2019-05-13 10:16:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:32 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:16:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:17:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:18:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:19:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:20:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:21:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:22:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:23:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:24:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:45 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:50 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:25:55 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:00 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:10 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:25 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:30 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:35 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

2019-05-13 10:26:40 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "E:\python36\lib\site-packages\scrapy\commands\crawl.py", line 58, in run
    self.crawler_process.start()
  File "E:\python36\lib\site-packages\scrapy\crawler.py", line 293, in start
    reactor.run(installSignalHandlers=False)  # blocking call
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1267, in run
    self.mainLoop()
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 1276, in mainLoop
    self.runUntilCurrent()
--- <exception caught here> ---
  File "E:\python36\lib\site-packages\twisted\internet\base.py", line 902, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "E:\python36\lib\site-packages\scrapy\utils\reactor.py", line 41, in __call__
    return self._func(*self._a, **self._kw)
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 122, in _next_request
    if not self._next_request_from_scheduler(spider):
  File "E:\python36\lib\site-packages\scrapy\core\engine.py", line 149, in _next_request_from_scheduler
    request = slot.scheduler.next_request()
  File "E:\python36\lib\site-packages\scrapy_redis\scheduler.py", line 172, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "E:\python36\lib\site-packages\scrapy_redis\queue.py", line 115, in pop
    results, count = pipe.execute()
  File "E:\python36\lib\site-packages\redis\client.py", line 3514, in execute
    self.shard_hint)
  File "E:\python36\lib\site-packages\redis\connection.py", line 994, in get_connection
    connection.connect()
  File "E:\python36\lib\site-packages\redis\connection.py", line 497, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 10061 connecting to 127.0.0.1:6379. 由于目标计算机积极拒绝，无法连接。.

